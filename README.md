# Model Explainability

A **Shiny-based web application** that enables users to upload images and analyze how deep learning models make predictions. The app provides **two interpretability techniques**:

1. **Grad-CAM (Gradient-weighted Class Activation Mapping)** â€“ Highlights important regions in an image that contributed to a model's prediction.
2. **SHAP (SHapley Additive exPlanations)** â€“ A game-theoretic approach that assigns importance values to each pixel.

This project focuses on **XAI (Explainable AI)** techniques for deep learning with a clean, scalable architecture.

## ğŸ”¥ Features

- âœ… **Upload and Analyze Images** â€“ Users can upload an image and visualize explanations
- âœ… **Multiple Model Support** â€“ Select from models like **VGG16, ResNet50, MobileNetV2, and EfficientNet**
- âœ… **Grad-CAM Visualization** â€“ See heatmaps overlaying important regions
- âœ… **SHAP Interpretability** â€“ Generate pixel-based importance explanations
- âœ… **Confidence Threshold Slider** â€“ Customize the minimum prediction confidence for analysis
- âœ… **Interactive UI** â€“ Built with **Shiny and R**, integrating Python via `reticulate`
- âœ… **Modular Architecture** â€“ Clean separation of concerns with scalable folder structure

## ğŸ“ Project Structure

```
model-explainability/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ python/                    # Python explainability modules
â”‚   â”‚   â”œâ”€â”€ models/                # Model loading and management
â”‚   â”‚   â”œâ”€â”€ explainability/        # Grad-CAM and SHAP implementations
â”‚   â”‚   â”œâ”€â”€ utils/                 # Utility functions
â”‚   â”‚   â””â”€â”€ explainability_api.py  # Main API interface
â”‚   â””â”€â”€ shiny/                     # R Shiny application components
â”‚       â”œâ”€â”€ ui.R                   # User interface
â”‚       â”œâ”€â”€ server.R               # Server logic
â”‚       â””â”€â”€ modules/               # Modular Shiny components
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ python/                    # Python unit tests
â”‚   â””â”€â”€ r/                         # R tests
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ images/                    # Sample images and test data
â”‚   â””â”€â”€ docs/                      # Documentation and papers
â”œâ”€â”€ config/                        # Configuration files
â”œâ”€â”€ outputs/                       # Generated explanations (gitignored)
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ app.R                         # Main Shiny app entry point
â””â”€â”€ README.md
```

## ğŸ› ï¸ Installation & Setup

### **Prerequisites**
- **R (>= 4.0)**
- **Python (>= 3.8)**
- **Shiny Server** (for deployment)

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/rodrick-mpofu/model-explainability.git
cd model-explainability
```

### **2ï¸âƒ£ Install Python Dependencies**
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Install R Dependencies**
```r
# Install required R packages
install.packages(c("shiny", "shinydashboard", "shinythemes", 
                   "shinycssloaders", "reticulate", "png"))
```

### **4ï¸âƒ£ Configure Python Environment**
```r
# In R, configure reticulate to use your Python environment
library(reticulate)
use_python("/path/to/your/python")  # or use_virtualenv()
```

### **5ï¸âƒ£ Run the Application**
```r
# Run the Shiny app
shiny::runApp("app.R")
```

## ğŸ¯ How It Works

1. **Upload an Image** ğŸ“·
2. **Select Model & Technique** (Grad-CAM or SHAP) ğŸ—ï¸
3. **Adjust Confidence Threshold** ğŸšï¸
4. **View Model Explanation** ğŸ”¥ (Heatmaps for Grad-CAM / SHAP values for SHAP)
5. **Interpret Results** âœ…

## ğŸ Python API Usage

You can also use the Python API directly:

```python
from src.python.explainability_api import explain_image

# Generate Grad-CAM explanation
results = explain_image(
    img_path="assets/images/dog.jpg",
    model_name="vgg16",
    technique="gradcam",
    confidence_threshold=0.5
)

# Generate SHAP explanation  
results = explain_image(
    img_path="assets/images/dog.jpg",
    model_name="resnet50", 
    technique="shap",
    confidence_threshold=0.3
)
```

## ğŸ§ª Testing

Run the test suite:

```bash
# Python tests
python -m pytest tests/python/

# R tests (if available)
Rscript -e "testthat::test_dir('tests/r')"
```

## ğŸ“š Architecture Benefits

The new modular structure provides:

- **Separation of Concerns**: Clear separation between UI, business logic, and utilities
- **Scalability**: Easy to add new models and explanation techniques
- **Maintainability**: Well-organized code with proper imports and dependencies
- **Testability**: Dedicated test structure for both Python and R components
- **Reusability**: Python modules can be used independently of the Shiny app
- **Framework Conventions**: Follows best practices for both Python and R/Shiny

## ğŸ“¬ Contact & Contributions

- ğŸ‘¤ **Rodrick Mpofu**
- ğŸ“§ **Email**: rodrickmpofu@gmail.com
- ğŸ”— **GitHub**: [@rodrick-mpofu](https://github.com/rodrick-mpofu)
- ğŸ”— **LinkedIn**: [Rodrick Mpofu](https://www.linkedin.com/in/rodrick-mpofu/)

## ğŸ“„ License

This project is available under the MIT License. See LICENSE file for details.







